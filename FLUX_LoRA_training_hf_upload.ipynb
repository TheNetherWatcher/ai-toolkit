{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zl-S0m3pkQC5"
   },
   "source": [
    "# AI Toolkit by Ostris\n",
    "## FLUX.1-dev Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 10 00:12:18 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0             53W /  400W |       1MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvAG0GKAh59G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/ai-toolkit/dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFUW4ZMmnp1V"
   },
   "source": [
    "Put your image dataset in the `~/ai-toolkit/dataset` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XGZqVER_aQJW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 4))\n",
      "  Cloning https://github.com/huggingface/diffusers.git to /var/tmp/pip-req-build-bvyxz12v\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /var/tmp/pip-req-build-bvyxz12v\n",
      "  Resolved https://github.com/huggingface/diffusers.git to commit a26d57097a19489306dacf9340cfba29fe0b363a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.5.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.20.1)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.5.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.47.1)\n",
      "Requirement already satisfied: lycoris-lora==1.8.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.8.3)\n",
      "Requirement already satisfied: flatten_json in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.1.14)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: oyaml in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.0)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: kornia in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.7.4)\n",
      "Requirement already satisfied: invisible-watermark in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.8.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (1.2.1)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
      "Requirement already satisfied: albumentations==1.4.15 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (1.4.15)\n",
      "Requirement already satisfied: albucore==0.0.16 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (0.0.16)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (2.10.4)\n",
      "Requirement already satisfied: omegaconf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (2.3.0)\n",
      "Requirement already satisfied: k-diffusion in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (0.1.1.post1)\n",
      "Requirement already satisfied: open_clip_torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (2.30.0)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (1.0.12)\n",
      "Requirement already satisfied: prodigyopt in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (1.1.1)\n",
      "Requirement already satisfied: controlnet_aux==0.0.7 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (0.0.7)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (1.0.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 26)) (0.45.0)\n",
      "Requirement already satisfied: hf_transfer in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (0.1.9)\n",
      "Requirement already satisfied: lpips in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.1.4)\n",
      "Requirement already satisfied: pytorch_fid in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 29)) (0.3.0)\n",
      "Requirement already satisfied: optimum-quanto==0.2.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 30)) (0.2.4)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (0.2.0)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 32)) (0.27.1)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 33)) (0.14.0)\n",
      "Requirement already satisfied: gradio in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (5.10.0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 35)) (8.0.4)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.11.4)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.24.0)\n",
      "Requirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.2.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (4.10.0.84)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (8.4.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (4.10.0.84)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.16.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (11.0.0)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from optimum-quanto==0.2.4->-r requirements.txt (line 30)) (1.11.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.33.0.dev0->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers==0.33.0.dev0->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (24.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (4.67.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from flatten_json->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (1.68.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (75.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (3.1.3)\n",
      "Requirement already satisfied: kornia-rs>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from kornia->-r requirements.txt (line 11)) (0.1.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from invisible-watermark->-r requirements.txt (line 12)) (1.7.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 14)) (5.9.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 18)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 18)) (2.27.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.10/site-packages (from omegaconf->-r requirements.txt (line 19)) (4.9.3)\n",
      "Requirement already satisfied: clean-fid in /opt/conda/lib/python3.10/site-packages (from k-diffusion->-r requirements.txt (line 20)) (0.1.35)\n",
      "Requirement already satisfied: clip-anytorch in /opt/conda/lib/python3.10/site-packages (from k-diffusion->-r requirements.txt (line 20)) (2.6.0)\n",
      "Requirement already satisfied: dctorch in /opt/conda/lib/python3.10/site-packages (from k-diffusion->-r requirements.txt (line 20)) (0.1.2)\n",
      "Requirement already satisfied: jsonmerge in /opt/conda/lib/python3.10/site-packages (from k-diffusion->-r requirements.txt (line 20)) (1.9.2)\n",
      "Requirement already satisfied: torchdiffeq in /opt/conda/lib/python3.10/site-packages (from k-diffusion->-r requirements.txt (line 20)) (0.2.5)\n",
      "Requirement already satisfied: torchsde in /opt/conda/lib/python3.10/site-packages (from k-diffusion->-r requirements.txt (line 20)) (0.2.6)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from k-diffusion->-r requirements.txt (line 20)) (0.19.1)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from open_clip_torch->-r requirements.txt (line 21)) (6.3.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (4.6.2.post1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.115.5)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.5.3 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (1.5.3)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.28.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (3.10.13)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (2.0.3)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.8.6)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.13.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.32.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.3->gradio->-r requirements.txt (line 34)) (14.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->-r requirements.txt (line 35)) (1.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.2.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (13.9.4)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip_torch->-r requirements.txt (line 21)) (0.2.13)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.21.0)\n",
      "Requirement already satisfied: jsonschema>2.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 20)) (4.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.33.0.dev0->-r requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.33.0.dev0->-r requirements.txt (line 4)) (1.26.20)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from torchsde->k-diffusion->-r requirements.txt (line 20)) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (4.3.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (1.3.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (4.0.11)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!cd ~/ai-toolkit && pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV0HnOI6o8V6"
   },
   "source": [
    "## Model License\n",
    "Training currently only works with FLUX.1-dev. Which means anything you train will inherit the non-commercial license. It is also a gated model, so you need to accept the license on HF before using it. Otherwise, this will fail. Here are the required steps to setup a license.\n",
    "\n",
    "Sign into HF and accept the model access here [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)\n",
    "\n",
    "[Get a READ key from huggingface](https://huggingface.co/settings/tokens/new?) and place it in the next cell after running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3yZZdhFRoj2m",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN environment variable has been set.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Prompt for the token\n",
    "hf_token = \"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\"\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "\n",
    "print(\"HF_TOKEN environment variable has been set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9gO2EzQ1kQC8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from itertools import product\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(cwd)\n",
    "from toolkit.job import run_job\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8UUFzVRigbC"
   },
   "source": [
    "## Setup\n",
    "\n",
    "This is your config. It is documented pretty well. Normally you would do this as a yaml file, but for colab, this will work. This will run as is without modification, but feel free to edit as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"STEPS\": 5,\n",
    "        \"LEARNING_RATE\": 4e-4,\n",
    "        \"DATASET\": \"og-chair-bg\",\n",
    "        \"TRAINING_TYPE\": \"balanced\",\n",
    "        \"LORA_RANK\": 16,\n",
    "        \"SAVE_EVERY\": 2,\n",
    "        \"CAPTION_DROPOUT_RATE\": 0.00,\n",
    "        \"SAMPLE_EVERY\": 100,\n",
    "        \"SAMPLING_PROMPT\": [],\n",
    "        \"SEED\": 42,\n",
    "        \"SAMPLING_STEPS\": 1,\n",
    "        \"LAYERS\": [\n",
    "            \"transformer.single_transformer_blocks.7.proj_out\",\n",
    "            \"transformer.single_transformer_blocks.12.proj_out\",\n",
    "            \"transformer.single_transformer_blocks.16.proj_out\",\n",
    "            \"transformer.single_transformer_blocks.20.proj_out\"\n",
    "        ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params[\"LAYERS\"]:\n",
    "    lora_name = f\"{params['DATASET']}-steps{params['STEPS']}-lr{params['LEARNING_RATE']}-lrank{params['LORA_RANK']}-b1_layers\"\n",
    "    output_path = f\"{cwd}/{lora_name}\"\n",
    "    for i in params[\"LAYERS\"]:\n",
    "        lora_name += f\"-{i.split('.')[-2]}\"\n",
    "    job_to_run = OrderedDict([\n",
    "        ('job', 'extension'),\n",
    "        ('config', OrderedDict([\n",
    "            ('name', lora_name),\n",
    "            ('process', [\n",
    "                OrderedDict([\n",
    "                    ('type', 'sd_trainer'),\n",
    "                    ('training_folder', f'{cwd}/output'),\n",
    "                    ('performance_log_every', 1000),\n",
    "                    ('device', 'cuda:0'),\n",
    "                    ('network', OrderedDict([\n",
    "                        ('type', 'lora'),\n",
    "                        ('linear', params[\"LORA_RANK\"]),\n",
    "                        ('linear_alpha', 16),\n",
    "                        ('network_kwargs', OrderedDict([\n",
    "                            ('only_if_contains', params[\"LAYERS\"])\n",
    "                        ]))\n",
    "                    ])),\n",
    "                    ('save', OrderedDict([\n",
    "                        ('dtype', 'float16'),\n",
    "                        ('save_every', params[\"SAVE_EVERY\"]),\n",
    "                        ('max_step_saves_to_keep', 4000)\n",
    "                    ])),\n",
    "                    ('datasets', [\n",
    "                        OrderedDict([\n",
    "                            ('folder_path', f'{cwd}/dataset/{params[\"DATASET\"]}'),\n",
    "                            ('caption_ext', 'txt'),\n",
    "                            ('caption_dropout_rate', params[\"CAPTION_DROPOUT_RATE\"]),\n",
    "                            ('shuffle_tokens', False),\n",
    "                            ('cache_latents_to_disk', True),\n",
    "                            ('resolution', [512, 768, 1024])\n",
    "                        ])\n",
    "                    ]),\n",
    "                    ('train', OrderedDict([\n",
    "                        ('batch_size', 1),\n",
    "                        ('steps', params[\"STEPS\"]),\n",
    "                        ('gradient_accumulation_steps', 1),\n",
    "                        ('train_unet', True),\n",
    "                        ('train_text_encoder', False),\n",
    "                        ('content_or_style', params[\"TRAINING_TYPE\"]),\n",
    "                        ('gradient_checkpointing', True),\n",
    "                        ('noise_scheduler', 'flowmatch'),\n",
    "                        ('optimizer', 'adamw8bit'),\n",
    "                        ('lr', params[\"LEARNING_RATE\"]),\n",
    "                        ('skip_first_sample', True),\n",
    "                        ('ema_config', OrderedDict([\n",
    "                            ('use_ema', True),\n",
    "                            ('ema_decay', 0.99)\n",
    "                        ])),\n",
    "                        ('dtype', 'bf16')\n",
    "                    ])),\n",
    "                    ('model', OrderedDict([\n",
    "                        ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n",
    "                        ('is_flux', True),\n",
    "                        ('quantize', False),\n",
    "                    ])),\n",
    "                    ('sample', OrderedDict([\n",
    "                        ('sampler', 'flowmatch'),\n",
    "                        ('sample_every', params[\"SAMPLE_EVERY\"]),\n",
    "                        ('width', 1024),\n",
    "                        ('height', 1024),\n",
    "                        ('prompts', params[\"SAMPLING_PROMPT\"]),\n",
    "                        ('neg', ''),\n",
    "                        ('seed', params[\"SEED\"]),\n",
    "                        ('walk_seed', True),\n",
    "                        ('guidance_scale', 4),\n",
    "                        ('sample_steps', params[\"SAMPLING_STEPS\"])\n",
    "                    ]))\n",
    "                ])\n",
    "            ])\n",
    "        ])),\n",
    "        ('meta', OrderedDict([\n",
    "            ('name', lora_name),\n",
    "            ('version', '1.0')\n",
    "        ]))\n",
    "    ])\n",
    "else:\n",
    "    lora_name = f\"{params['DATASET']}-steps{params['STEPS']}-lr{params['LEARNING_RATE']}-lrank{params['LORA_RANK']}-b1_full-layer\"\n",
    "    job_to_run = OrderedDict([\n",
    "        ('job', 'extension'),\n",
    "        ('config', OrderedDict([\n",
    "            ('name', lora_name),\n",
    "            ('process', [\n",
    "                OrderedDict([\n",
    "                    ('type', 'sd_trainer'),\n",
    "                    ('training_folder', f'{cwd}/output'),\n",
    "                    ('performance_log_every', 1000),\n",
    "                    ('device', 'cuda:0'),\n",
    "                    ('network', OrderedDict([\n",
    "                        ('type', 'lora'),\n",
    "                        ('linear', params[\"LORA_RANK\"]),\n",
    "                        ('linear_alpha', 16)\n",
    "                    ])),\n",
    "                    ('save', OrderedDict([\n",
    "                        ('dtype', 'float16'),\n",
    "                        ('save_every', params[\"SAVE_EVERY\"]),\n",
    "                        ('max_step_saves_to_keep', 4000)\n",
    "                    ])),\n",
    "                    ('datasets', [\n",
    "                        OrderedDict([\n",
    "                            ('folder_path', f'{cwd}/dataset/{params[\"DATASET\"]}'),\n",
    "                            ('caption_ext', 'txt'),\n",
    "                            ('caption_dropout_rate', params[\"CAPTION_DROPOUT_RATE\"]),\n",
    "                            ('shuffle_tokens', False),\n",
    "                            ('cache_latents_to_disk', True),\n",
    "                            ('resolution', [512, 768, 1024])\n",
    "                        ])\n",
    "                    ]),\n",
    "                    ('train', OrderedDict([\n",
    "                        ('batch_size', 1),\n",
    "                        ('steps', params[\"STEPS\"]),\n",
    "                        ('gradient_accumulation_steps', 1),\n",
    "                        ('train_unet', True),\n",
    "                        ('train_text_encoder', False),\n",
    "                        ('content_or_style', params[\"TRAINING_TYPE\"]),\n",
    "                        ('gradient_checkpointing', True),\n",
    "                        ('noise_scheduler', 'flowmatch'),\n",
    "                        ('optimizer', 'adamw8bit'),\n",
    "                        ('lr', params[\"LEARNING_RATE\"]),\n",
    "                        ('skip_first_sample', True),\n",
    "                        ('ema_config', OrderedDict([\n",
    "                            ('use_ema', True),\n",
    "                            ('ema_decay', 0.99)\n",
    "                        ])),\n",
    "                        ('dtype', 'bf16')\n",
    "                    ])),\n",
    "                    ('model', OrderedDict([\n",
    "                        ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n",
    "                        ('is_flux', True),\n",
    "                        ('quantize', False),\n",
    "                    ])),\n",
    "                    ('sample', OrderedDict([\n",
    "                        ('sampler', 'flowmatch'),\n",
    "                        ('sample_every', params[\"SAMPLE_EVERY\"]),\n",
    "                        ('width', 1024),\n",
    "                        ('height', 1024),\n",
    "                        ('prompts', params[\"SAMPLING_PROMPT\"]),\n",
    "                        ('neg', ''),\n",
    "                        ('seed', params[\"SEED\"]),\n",
    "                        ('walk_seed', True),\n",
    "                        ('guidance_scale', 4),\n",
    "                        ('sample_steps', params[\"SAMPLING_STEPS\"])\n",
    "                    ]))\n",
    "                ])\n",
    "            ])\n",
    "        ])),\n",
    "        ('meta', OrderedDict([\n",
    "            ('name', lora_name),\n",
    "            ('version', '1.0')\n",
    "        ]))\n",
    "    ])\n",
    "    \n",
    "output_path = f\"{cwd}/output/{lora_name}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"type\": \"sd_trainer\",\n",
      "    \"training_folder\": \"/home/bhara/ai-toolkit/output\",\n",
      "    \"performance_log_every\": 1000,\n",
      "    \"device\": \"cuda:0\",\n",
      "    \"network\": {\n",
      "        \"type\": \"lora\",\n",
      "        \"linear\": 16,\n",
      "        \"linear_alpha\": 16,\n",
      "        \"network_kwargs\": {\n",
      "            \"only_if_contains\": [\n",
      "                \"transformer.single_transformer_blocks.7.proj_out\",\n",
      "                \"transformer.single_transformer_blocks.12.proj_out\",\n",
      "                \"transformer.single_transformer_blocks.16.proj_out\",\n",
      "                \"transformer.single_transformer_blocks.20.proj_out\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"save\": {\n",
      "        \"dtype\": \"float16\",\n",
      "        \"save_every\": 2,\n",
      "        \"max_step_saves_to_keep\": 4000\n",
      "    },\n",
      "    \"datasets\": [\n",
      "        {\n",
      "            \"folder_path\": \"/home/bhara/ai-toolkit/dataset/og-chair-bg\",\n",
      "            \"caption_ext\": \"txt\",\n",
      "            \"caption_dropout_rate\": 0.0,\n",
      "            \"shuffle_tokens\": false,\n",
      "            \"cache_latents_to_disk\": true,\n",
      "            \"resolution\": [\n",
      "                512,\n",
      "                768,\n",
      "                1024\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"train\": {\n",
      "        \"batch_size\": 1,\n",
      "        \"steps\": 5,\n",
      "        \"gradient_accumulation_steps\": 1,\n",
      "        \"train_unet\": true,\n",
      "        \"train_text_encoder\": false,\n",
      "        \"content_or_style\": \"balanced\",\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"noise_scheduler\": \"flowmatch\",\n",
      "        \"optimizer\": \"adamw8bit\",\n",
      "        \"lr\": 0.0004,\n",
      "        \"skip_first_sample\": true,\n",
      "        \"ema_config\": {\n",
      "            \"use_ema\": true,\n",
      "            \"ema_decay\": 0.99\n",
      "        },\n",
      "        \"dtype\": \"bf16\"\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n",
      "        \"is_flux\": true,\n",
      "        \"quantize\": false\n",
      "    },\n",
      "    \"sample\": {\n",
      "        \"sampler\": \"flowmatch\",\n",
      "        \"sample_every\": 100,\n",
      "        \"width\": 1024,\n",
      "        \"height\": 1024,\n",
      "        \"prompts\": [],\n",
      "        \"neg\": \"\",\n",
      "        \"seed\": 42,\n",
      "        \"walk_seed\": true,\n",
      "        \"guidance_scale\": 4,\n",
      "        \"sample_steps\": 1\n",
      "    }\n",
      "}\n",
      "Using EMA\n",
      "\n",
      "#############################################\n",
      "# Running job: og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20\n",
      "#############################################\n",
      "\n",
      "\n",
      "Running  1 process\n",
      "Loading Flux model\n",
      "Loading transformer\n",
      "Loading vae\n",
      "Loading t5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c9319fc39141fe8bc4b6e6f8ae59d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4569ab2118384eb081ccade74f2f0367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clip\n",
      "making pipe\n",
      "preparing\n",
      "create LoRA network. base dim (rank): 16, alpha: 16\n",
      "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
      "create LoRA for Text Encoder: 0 modules.\n",
      "create LoRA for U-Net: 4 modules.\n",
      "enable LoRA for U-Net\n",
      "#### IMPORTANT RESUMING FROM /home/bhara/ai-toolkit/output/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20_000000004.safetensors ####\n",
      "Loading from /home/bhara/ai-toolkit/output/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20_000000004.safetensors\n",
      "Missing keys: []\n",
      "Found step 4 in metadata, starting from there\n",
      "Loading optimizer state from /home/bhara/ai-toolkit/output/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20/optimizer.pt\n",
      "Updating optimizer LR from params\n",
      "Dataset: /home/bhara/ai-toolkit/dataset/og-chair-bg\n",
      "  -  Preprocessing image dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 38335.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  Found 22 images\n",
      "Bucket sizes for /home/bhara/ai-toolkit/dataset/og-chair-bg:\n",
      "576x384: 9 files\n",
      "384x576: 13 files\n",
      "2 buckets made\n",
      "Caching latents for /home/bhara/ai-toolkit/dataset/og-chair-bg\n",
      " - Saving latents to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching latents to disk: 100%|███████████████████████████████████████████████████████| 22/22 [00:00<00:00, 21232.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: /home/bhara/ai-toolkit/dataset/og-chair-bg\n",
      "  -  Preprocessing image dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 41772.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  Found 22 images\n",
      "Bucket sizes for /home/bhara/ai-toolkit/dataset/og-chair-bg:\n",
      "832x576: 9 files\n",
      "576x832: 13 files\n",
      "2 buckets made\n",
      "Caching latents for /home/bhara/ai-toolkit/dataset/og-chair-bg\n",
      " - Saving latents to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching latents to disk: 100%|███████████████████████████████████████████████████████| 22/22 [00:00<00:00, 21675.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: /home/bhara/ai-toolkit/dataset/og-chair-bg\n",
      "  -  Preprocessing image dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 22/22 [00:00<00:00, 41885.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -  Found 22 images\n",
      "Bucket sizes for /home/bhara/ai-toolkit/dataset/og-chair-bg:\n",
      "1216x832: 9 files\n",
      "832x1216: 13 files\n",
      "2 buckets made\n",
      "Caching latents for /home/bhara/ai-toolkit/dataset/og-chair-bg\n",
      " - Saving latents to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching latents to disk: 100%|███████████████████████████████████████████████████████| 22/22 [00:00<00:00, 12100.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping first sample due to config setting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20:  80%|████▊ | 4/5 [00:00<?, ?it/s, lr: 4.0e-04 loss: 2.646e-01]\n",
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved to /home/bhara/ai-toolkit/output/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20/optimizer.pt\n"
     ]
    }
   ],
   "source": [
    "run_job(job_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20.safetensors' not found in the folder '/home/bhara/ai-toolkit/output/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20/'.\n"
     ]
    }
   ],
   "source": [
    "def rename_file(folder_path, old_filename, new_filename):\n",
    "    old_file_path = os.path.join(folder_path, old_filename)\n",
    "    new_file_path = os.path.join(folder_path, new_filename)\n",
    "\n",
    "    if not os.path.exists(old_file_path):\n",
    "        print(f\"Error: '{old_filename}' not found in the folder '{folder_path}'.\")\n",
    "        return\n",
    "\n",
    "    if os.path.exists(new_file_path):\n",
    "        print(f\"Error: A file with the name '{new_filename}' already exists in the folder.\")\n",
    "        return\n",
    "\n",
    "    os.rename(old_file_path, new_file_path)\n",
    "\n",
    "old_filename = f\"{lora_name}.safetensors\"\n",
    "new_filename = \"lora.safetensors\"\n",
    "\n",
    "rename_file(output_path, old_filename, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_username_from_token(hf_token):\n",
    "    url = \"https://huggingface.co/api/whoami-v2\"\n",
    "    headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get(\"name\", \"Username not found\")\n",
    "    else:\n",
    "        return f\"Error: Unable to fetch username (Status Code: {response.status_code})\"\n",
    "\n",
    "username = get_username_from_token(hf_token)\n",
    "repo = f\"{username}/{lora_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/TheNetherWatcherv2/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20', endpoint='https://huggingface.co', repo_type='model', repo_id='TheNetherWatcherv2/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.create_repo(\n",
    "    repo_id=repo,\n",
    "    token=hf_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367485d5dd4842beba1fea6e8d40e63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc741bebb384671bbc8a061739330d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20.safetensors:   0%|          | 0.00/2.36M [00:00<?, ?B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/TheNetherWatcherv2/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20/commit/2bf70e7bcb9c35ccf6f2c81b9447985a73bb9320', commit_message='Upload lora.safetensors with huggingface_hub', commit_description='', oid='2bf70e7bcb9c35ccf6f2c81b9447985a73bb9320', pr_url=None, repo_url=RepoUrl('https://huggingface.co/TheNetherWatcherv2/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20', endpoint='https://huggingface.co', repo_type='model', repo_id='TheNetherWatcherv2/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj=f\"{output_path}/{lora_name}.safetensors\",\n",
    "    path_in_repo=\"lora.safetensors\",\n",
    "    repo_id=repo,\n",
    "    repo_type=\"model\",\n",
    "    token=hf_token,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/TheNetherWatcherv2/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20/commit/ee1bb413b72ed5c8e909155670b41a285304af97', commit_message='Upload config.yaml with huggingface_hub', commit_description='', oid='ee1bb413b72ed5c8e909155670b41a285304af97', pr_url=None, repo_url=RepoUrl('https://huggingface.co/TheNetherWatcherv2/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20', endpoint='https://huggingface.co', repo_type='model', repo_id='TheNetherWatcherv2/og-chair-bg-steps5-lr0.0004-lrank16-b1_layers-7-12-16-20'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj=f\"{output_path}/config.yaml\",\n",
    "    path_in_repo=\"config.yaml\",\n",
    "    repo_id=repo,\n",
    "    repo_type=\"model\",\n",
    "    token=hf_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f\"{output_path}/samples\"):\n",
    "    api.upload_folder(\n",
    "        folder_path=f\"{output_path}/samples\",\n",
    "        path_in_repo=\"./samples\",  # Path in the repository (root in this case)\n",
    "        repo_id=repo,\n",
    "        repo_type=\"model\",  # Change to 'dataset' if uploading to a dataset repo\n",
    "        # commit_message=commit_message,\n",
    "        token=hf_token\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
