{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zl-S0m3pkQC5"
   },
   "source": [
    "# AI Toolkit by Ostris\n",
    "## FLUX.1-dev Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  7 16:30:56 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   29C    P0             42W /  400W |       1MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BvAG0GKAh59G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/ai-toolkit/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFUW4ZMmnp1V"
   },
   "source": [
    "Put your image dataset in the `~/ai-toolkit/dataset` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XGZqVER_aQJW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule 'repositories/batch_annotator' (https://github.com/ostris/batch-annotator) registered for path 'repositories/batch_annotator'\n",
      "Submodule 'repositories/ipadapter' (https://github.com/tencent-ailab/IP-Adapter.git) registered for path 'repositories/ipadapter'\n",
      "Submodule 'repositories/leco' (https://github.com/p1atdev/LECO) registered for path 'repositories/leco'\n",
      "Submodule 'repositories/sd-scripts' (https://github.com/kohya-ss/sd-scripts.git) registered for path 'repositories/sd-scripts'\n",
      "Cloning into '/home/bhara/ai-toolkit/repositories/batch_annotator'...\n",
      "Cloning into '/home/bhara/ai-toolkit/repositories/ipadapter'...\n",
      "Cloning into '/home/bhara/ai-toolkit/repositories/leco'...\n",
      "Cloning into '/home/bhara/ai-toolkit/repositories/sd-scripts'...\n",
      "Submodule path 'repositories/batch_annotator': checked out '420e142f6ad3cc14b3ea0500affc2c6c7e7544bf'\n",
      "Submodule 'repositories/controlnet' (https://github.com/lllyasviel/ControlNet-v1-1-nightly.git) registered for path 'repositories/batch_annotator/repositories/controlnet'\n",
      "Cloning into '/home/bhara/ai-toolkit/repositories/batch_annotator/repositories/controlnet'...\n",
      "Submodule path 'repositories/batch_annotator/repositories/controlnet': checked out 'e2b44154b72965c5e11b1ccee941d550682e4701'\n",
      "Submodule path 'repositories/ipadapter': checked out '5a18b1f3660acaf8bee8250692d6fb3548a19b14'\n",
      "Submodule path 'repositories/leco': checked out '9294adf40218e917df4516737afb13f069a6789d'\n",
      "Submodule path 'repositories/sd-scripts': checked out 'b78c0e2a69e52ce6c79abc6c8c82d1a9cabcf05c'\n",
      "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 4))\n",
      "  Cloning https://github.com/huggingface/diffusers.git to /var/tmp/pip-req-build-t90ibavb\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /var/tmp/pip-req-build-t90ibavb\n",
      "  Resolved https://github.com/huggingface/diffusers.git to commit 03bcf5aefef13a064c34b605e489c0730052cca8\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch (from -r requirements.txt (line 1))\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision (from -r requirements.txt (line 2))\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting safetensors (from -r requirements.txt (line 3))\n",
      "  Downloading safetensors-0.5.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting transformers (from -r requirements.txt (line 5))\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 6))\n",
      "  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting flatten_json (from -r requirements.txt (line 7))\n",
      "  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
      "Collecting oyaml (from -r requirements.txt (line 9))\n",
      "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tensorboard (from -r requirements.txt (line 10))\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting kornia (from -r requirements.txt (line 11))\n",
      "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting invisible-watermark (from -r requirements.txt (line 12))\n",
      "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting einops (from -r requirements.txt (line 13))\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting accelerate (from -r requirements.txt (line 14))\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting toml (from -r requirements.txt (line 15))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting albumentations==1.4.15 (from -r requirements.txt (line 16))\n",
      "  Downloading albumentations-1.4.15-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting albucore==0.0.16 (from -r requirements.txt (line 17))\n",
      "  Downloading albucore-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (1.10.19)\n",
      "Collecting omegaconf (from -r requirements.txt (line 19))\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting k-diffusion (from -r requirements.txt (line 20))\n",
      "  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting open_clip_torch (from -r requirements.txt (line 21))\n",
      "  Downloading open_clip_torch-2.30.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting timm (from -r requirements.txt (line 22))\n",
      "  Downloading timm-1.0.12-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting prodigyopt (from -r requirements.txt (line 23))\n",
      "  Downloading prodigyopt-1.1.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting controlnet_aux==0.0.7 (from -r requirements.txt (line 24))\n",
      "  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (1.0.1)\n",
      "Collecting bitsandbytes (from -r requirements.txt (line 26))\n",
      "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting hf_transfer (from -r requirements.txt (line 27))\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting lpips (from -r requirements.txt (line 28))\n",
      "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pytorch_fid (from -r requirements.txt (line 29))\n",
      "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting optimum-quanto==0.2.4 (from -r requirements.txt (line 30))\n",
      "  Downloading optimum_quanto-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sentencepiece (from -r requirements.txt (line 31))\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface_hub (from -r requirements.txt (line 32))\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting peft (from -r requirements.txt (line 33))\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting gradio (from -r requirements.txt (line 34))\n",
      "  Downloading gradio-5.10.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting python-slugify (from -r requirements.txt (line 35))\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.11.4)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.24.0)\n",
      "Collecting pydantic (from -r requirements.txt (line 18))\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting eval-type-backport (from albumentations==1.4.15->-r requirements.txt (line 16))\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations==1.4.15->-r requirements.txt (line 16))\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: importlib_metadata in /opt/conda/lib/python3.10/site-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (8.4.0)\n",
      "Collecting opencv-python (from controlnet_aux==0.0.7->-r requirements.txt (line 24))\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.16.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (11.0.0)\n",
      "Collecting ninja (from optimum-quanto==0.2.4->-r requirements.txt (line 30))\n",
      "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->-r requirements.txt (line 1))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting regex!=2019.12.17 (from diffusers==0.33.0.dev0->-r requirements.txt (line 4))\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers==0.33.0.dev0->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (24.1)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 5))\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (4.67.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from flatten_json->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (1.68.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 10))\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 10)) (75.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 10))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 10))\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting kornia-rs>=0.1.0 (from kornia->-r requirements.txt (line 11))\n",
      "  Downloading kornia_rs-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from invisible-watermark->-r requirements.txt (line 12)) (1.7.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 14)) (5.9.3)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->-r requirements.txt (line 18))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic->-r requirements.txt (line 18))\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 19))\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting clean-fid (from k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting dctorch (from k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n",
      "Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
      "Collecting torchsde (from k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting wandb (from k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading wandb-0.19.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting ftfy (from open_clip_torch->-r requirements.txt (line 21))\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (4.6.2.post1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.115.5)\n",
      "Collecting ffmpy (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.5.3 (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading gradio_client-1.5.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading orjson-3.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (2.0.3)\n",
      "Collecting pydub (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.8.6)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.41.3)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio->-r requirements.txt (line 34))\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.13.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 34)) (0.32.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.3->gradio->-r requirements.txt (line 34)) (14.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->-r requirements.txt (line 35))\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.2.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio->-r requirements.txt (line 34))\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (0.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (13.9.4)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip_torch->-r requirements.txt (line 21)) (0.2.13)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib_metadata->controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.21.0)\n",
      "Requirement already satisfied: jsonschema>2.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 20)) (4.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.33.0.dev0->-r requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.33.0.dev0->-r requirements.txt (line 4)) (1.26.20)\n",
      "Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (4.3.6)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading sentry_sdk-2.19.2-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting setproctitle (from wandb->k-diffusion->-r requirements.txt (line 20))\n",
      "  Downloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (4.0.11)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (5.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (0.1.2)\n",
      "Downloading albumentations-1.4.15-py3-none-any.whl (200 kB)\n",
      "Downloading albucore-0.0.16-py3-none-any.whl (9.5 kB)\n",
      "Downloading optimum_quanto-0.2.4-py3-none-any.whl (109 kB)\n",
      "Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m174.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m190.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m146.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m167.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m169.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
      "Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Downloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n",
      "Downloading open_clip_torch-2.30.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-1.0.12-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m146.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prodigyopt-1.1.1-py3-none-any.whl (7.4 kB)\n",
      "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m138.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
      "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Downloading gradio-5.10.0-py3-none-any.whl (57.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.5.3-py3-none-any.whl (320 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading kornia_rs-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m154.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m171.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
      "Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Downloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
      "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
      "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
      "Downloading wandb-0.19.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m188.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.19.2-py2.py3-none-any.whl (322 kB)\n",
      "Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
      "Downloading setproctitle-1.3.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Building wheels for collected packages: lycoris-lora, controlnet_aux, diffusers, antlr4-python3-runtime\n",
      "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lycoris-lora: filename=lycoris_lora-1.8.3-py3-none-any.whl size=77134 sha256=0a4ee58a70cbc0960948e74cbe6cecc768625e2aae790cb7fefc6062f08a1b0f\n",
      "  Stored in directory: /home/bhara/.cache/pip/wheels/1b/d8/ac/e1feba5dec18685dac32ff2465ea1908cbe6a919a0c008a215\n",
      "  Building wheel for controlnet_aux (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274344 sha256=184b0ad05e0139b8f6b8b829ad34f8c41a86f1523639f8ad86f1b2e0f2c8725b\n",
      "  Stored in directory: /home/bhara/.cache/pip/wheels/1e/3e/93/6678b4c0bc2ec31d53409b25d4189cbb08bae843e8b2b78e52\n",
      "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.33.0.dev0-py3-none-any.whl size=3228912 sha256=c26e874cb84b0d111b6ee629714093cf39371a2af4abd9ebce92bcae8dd6ac17\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-doctc66s/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144556 sha256=16edb13f4d2dfa4c04941f0b091efe988b0811cfbb446d9bbc6503564005a60f\n",
      "  Stored in directory: /home/bhara/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built lycoris-lora controlnet_aux diffusers antlr4-python3-runtime\n",
      "Installing collected packages: trampoline, text-unidecode, sentencepiece, pydub, mpmath, antlr4-python3-runtime, triton, tomlkit, toml, tensorboard-data-server, sympy, setproctitle, sentry-sdk, semantic-version, safetensors, regex, python-slugify, python-multipart, pydantic-core, prodigyopt, oyaml, orjson, opencv-python-headless, opencv-python, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, markupsafe, markdown, kornia-rs, httpcore, hf_transfer, ftfy, flatten_json, ffmpy, eval-type-backport, einops, docker-pycreds, annotated-types, werkzeug, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, httpx, albucore, wandb, tokenizers, tensorboard, safehttpx, nvidia-cusolver-cu12, gradio-client, diffusers, albumentations, transformers, torch, jsonmerge, gradio, torchvision, torchsde, torchdiffeq, optimum-quanto, lycoris-lora, kornia, invisible-watermark, dctorch, bitsandbytes, accelerate, timm, pytorch_fid, peft, lpips, clip-anytorch, clean-fid, open_clip_torch, k-diffusion, controlnet_aux\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.19\n",
      "    Uninstalling pydantic-1.10.19:\n",
      "      Successfully uninstalled pydantic-1.10.19\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dataproc-jupyter-plugin 0.1.80 requires pydantic~=1.10.0, but you have pydantic 2.10.4 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.10.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.2.1 albucore-0.0.16 albumentations-1.4.15 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 bitsandbytes-0.45.0 clean-fid-0.1.35 clip-anytorch-2.6.0 controlnet_aux-0.0.7 dctorch-0.1.2 diffusers-0.33.0.dev0 docker-pycreds-0.4.0 einops-0.8.0 eval-type-backport-0.2.2 ffmpy-0.5.0 flatten_json-0.1.14 ftfy-6.3.1 gradio-5.10.0 gradio-client-1.5.3 hf_transfer-0.1.9 httpcore-1.0.7 httpx-0.28.1 huggingface_hub-0.27.1 invisible-watermark-0.2.0 jsonmerge-1.9.2 k-diffusion-0.1.1.post1 kornia-0.7.4 kornia-rs-0.1.8 lpips-0.1.4 lycoris-lora-1.8.3 markdown-3.7 markupsafe-2.1.5 mpmath-1.3.0 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 omegaconf-2.3.0 open_clip_torch-2.30.0 opencv-python-4.10.0.84 opencv-python-headless-4.10.0.84 optimum-quanto-0.2.4 orjson-3.10.13 oyaml-1.0 peft-0.14.0 prodigyopt-1.1.1 pydantic-2.10.4 pydantic-core-2.27.2 pydub-0.25.1 python-multipart-0.0.20 python-slugify-8.0.4 pytorch_fid-0.3.0 regex-2024.11.6 safehttpx-0.1.6 safetensors-0.5.1 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.19.2 setproctitle-1.3.4 sympy-1.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 text-unidecode-1.3 timm-1.0.12 tokenizers-0.21.0 toml-0.10.2 tomlkit-0.13.2 torch-2.5.1 torchdiffeq-0.2.5 torchsde-0.2.6 torchvision-0.20.1 trampoline-0.1.2 transformers-4.47.1 triton-3.1.0 wandb-0.19.1 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!cd ~/ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV0HnOI6o8V6"
   },
   "source": [
    "## Model License\n",
    "Training currently only works with FLUX.1-dev. Which means anything you train will inherit the non-commercial license. It is also a gated model, so you need to accept the license on HF before using it. Otherwise, this will fail. Here are the required steps to setup a license.\n",
    "\n",
    "Sign into HF and accept the model access here [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)\n",
    "\n",
    "[Get a READ key from huggingface](https://huggingface.co/settings/tokens/new?) and place it in the next cell after running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3yZZdhFRoj2m",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN environment variable has been set.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Prompt for the token\n",
    "hf_token = \"\"\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "\n",
    "print(\"HF_TOKEN environment variable has been set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9gO2EzQ1kQC8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/bhara/ai-toolkit')\n",
    "from toolkit.job import run_job\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8UUFzVRigbC"
   },
   "source": [
    "## Setup\n",
    "\n",
    "This is your config. It is documented pretty well. Normally you would do this as a yaml file, but for colab, this will work. This will run as is without modification, but feel free to edit as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Define your parameters\n",
    "parameters = {\n",
    "    \"STEPS\": 5000,\n",
    "    \"LEARNING_RATE\": 1e-4,\n",
    "    \"DATASET\": \"og-chair-bg\",\n",
    "    \"TRAINING_TYPE\": \"balanced\",\n",
    "    \"LORA_RANK\": 16,\n",
    "    \"SAVE_EVERY\": 250,\n",
    "    \"CAPTION_DROPOUT_RATE\": 0.05,\n",
    "    \"SAMPLE_EVERY\": 250,\n",
    "    \"SAMPLING_PROMPT\": [\n",
    "        'woman with red hair, playing chess at the park, bomb going off in the background',\n",
    "        'a woman holding a coffee cup, in a beanie, sitting at a cafe',\n",
    "        'a horse is a DJ at a night club, fish eye lens, smoke machine, lazer lights, holding a martini',\n",
    "        'a man showing off his cool new t shirt at the beach, a shark is jumping out of the water in the background',\n",
    "        'a bear building a log cabin in the snow covered mountains',\n",
    "        'woman playing the guitar, on stage, singing a song, laser lights, punk rocker',\n",
    "        'hipster man with a beard, building a chair, in a wood shop',\n",
    "        'photo of a man, white background, medium shot, modeling clothing, studio lighting, white backdrop',\n",
    "        'a man holding a sign that says, \"this is a sign\"',\n",
    "        'a bulldog, in a post apocalyptic world, with a shotgun, in a leather jacket, in a desert, with a motorcycle'\n",
    "    ],\n",
    "    \"SEED\": 42,\n",
    "    \"SAMPLING_STEPS\": 20,\n",
    "    \"LAYERS\": [\n",
    "        \"transformer.single_transformer_blocks.7.proj_out\",\n",
    "        \"transformer.single_transformer_blocks.12.proj_out\",\n",
    "        \"transformer.single_transformer_blocks.16.proj_out\",\n",
    "        \"transformer.single_transformer_blocks.20.proj_out\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    layers = \"\"\n",
    "    for i in parameters[\"LAYERS\"]:\n",
    "        layers += f\"-{i.split('.')[-2]}\"\n",
    "    print(layers)\n",
    "    lora_name = f\"{parameters['DATASET']}-steps{parameters['STEPS']}-lr{parameters['LEARNING_RATE']}-lrank{parameters['LORA_RANK']}-b1_layers{layers}\"\n",
    "except:\n",
    "    lora_name = f\"{parameters['DATASET']}-steps{parameters['STEPS']}-lr{parameters['LEARNING_RATE']}-lrank{parameters['LORA_RANK']}-b1_full-layer\"\n",
    "    \n",
    "print(lora_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t28QURYjRQO"
   },
   "outputs": [],
   "source": [
    "# Generate the configuration dynamically\n",
    "job_to_run = OrderedDict([\n",
    "    ('job', 'extension'),\n",
    "    ('config', OrderedDict([\n",
    "        ('name', lora_name),\n",
    "        ('process', [\n",
    "            OrderedDict([\n",
    "                ('type', 'sd_trainer'),\n",
    "                ('training_folder', '~/ai-toolkit/output'),\n",
    "                ('performance_log_every', 1000),\n",
    "                ('device', 'cuda:0'),\n",
    "                ('network', OrderedDict([\n",
    "                    ('type', 'lora'),\n",
    "                    ('linear', parameters[\"LORA_RANK\"]),\n",
    "                    ('linear_alpha', 16)\n",
    "                ])),\n",
    "                ('save', OrderedDict([\n",
    "                    ('dtype', 'float16'),\n",
    "                    ('save_every', parameters[\"SAVE_EVERY\"]),\n",
    "                    ('max_step_saves_to_keep', 4)\n",
    "                ])),\n",
    "                ('datasets', [\n",
    "                    OrderedDict([\n",
    "                        ('folder_path', f'/home/bhara/ai-toolkit/dataset/{parameters[\"DATASET\"]}'),\n",
    "                        ('caption_ext', 'txt'),\n",
    "                        ('caption_dropout_rate', parameters[\"CAPTION_DROPOUT_RATE\"]),\n",
    "                        ('shuffle_tokens', False),\n",
    "                        ('cache_latents_to_disk', True),\n",
    "                        ('resolution', [512, 768, 1024])\n",
    "                    ])\n",
    "                ]),\n",
    "                ('train', OrderedDict([\n",
    "                    ('batch_size', 1),\n",
    "                    ('steps', parameters[\"STEPS\"]),\n",
    "                    ('gradient_accumulation_steps', 1),\n",
    "                    ('train_unet', True),\n",
    "                    ('train_text_encoder', False),\n",
    "                    ('content_or_style', parameters[\"TRAINING_TYPE\"]),\n",
    "                    ('gradient_checkpointing', True),\n",
    "                    ('noise_scheduler', 'flowmatch'),\n",
    "                    ('optimizer', 'adamw8bit'),\n",
    "                    ('lr', parameters[\"LEARNING_RATE\"]),\n",
    "                    ('skip_first_sample', True),\n",
    "                    ('ema_config', OrderedDict([\n",
    "                        ('use_ema', True),\n",
    "                        ('ema_decay', 0.99)\n",
    "                    ])),\n",
    "                    ('dtype', 'bf16')\n",
    "                ])),\n",
    "                ('model', OrderedDict([\n",
    "                    ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n",
    "                    ('is_flux', True),\n",
    "                    ('quantize', False),\n",
    "                ])),\n",
    "                ('sample', OrderedDict([\n",
    "                    ('sampler', 'flowmatch'),\n",
    "                    ('sample_every', parameters[\"SAMPLE_EVERY\"]),\n",
    "                    ('width', 1024),\n",
    "                    ('height', 1024),\n",
    "                    ('prompts', parameters[\"SAMPLING_PROMPT\"]),\n",
    "                    ('neg', ''),\n",
    "                    ('seed', parameters[\"SEED\"]),\n",
    "                    ('walk_seed', True),\n",
    "                    ('guidance_scale', 4),\n",
    "                    ('sample_steps', parameters[\"SAMPLING_STEPS\"])\n",
    "                ]))\n",
    "            ])\n",
    "        ])\n",
    "    ])),\n",
    "    ('meta', OrderedDict([\n",
    "        ('name', lora_name),\n",
    "        ('version', '1.0')\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Print or use the updated configuration\n",
    "print(job_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6F1FlM2Wb3l"
   },
   "source": [
    "## Run it\n",
    "\n",
    "Below does all the magic. Check your folders to the left. Items will be in output/LoRA/your_name_v1 In the samples folder, there are preiodic sampled. This doesnt work great with colab. They will be in /content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkajwI8gteOh"
   },
   "outputs": [],
   "source": [
    "run_job(job_to_run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hblgb5uwW5SD"
   },
   "source": [
    "## Done\n",
    "\n",
    "Check your ourput dir and get your slider\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
